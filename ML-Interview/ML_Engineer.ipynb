{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuNUhs1C1Jou"
      },
      "source": [
        "### Author: Hoang Mau Trung\n",
        "### Position: Machine Learning Engineer\n",
        "### Email: hoangmautrung@gmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjzrO6HS1ObO"
      },
      "source": [
        "# Part 1: Theoretical Questions\n",
        "\n",
        "## 1.1 Why do GPT models only use the decoder part of the Transformer architecture?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Default Transformer models include 2 parts Encoder and Decoder. The encoder part is given inputs to capture context, it is rich information to support tasks such as machine translate or classification where context affects  final outputs. The decoder part uses to generate outputs.\n",
        "GPT models are designed for tasks that involve generating text based on a given context or prompt (autoregressive text generation) as context is unnecessary. They use decoder part with masked self-attention to create a model, which generates the next tokens based on previously generated tokens. It also makes a simple architecture and training process, allowing the model can be trained on vast amounts of unannotated text data to learn language patterns and structures. \n",
        "\n",
        "\n",
        "## 1.2 Explain the Attention mechanism in Transformer and why it is more effective than traditional RNN architectures. \n",
        "\n",
        "\n",
        "\n",
        "## 1.3 Explain the Chain-of-Thought technique. Analyze the advantages and disadvantages of this Prompt Engineering technique.\n",
        "\n",
        "* Explain CoT technique \n",
        "\n",
        "CoT is a way mimics human processing a complex task, it will break problem into simple step by step to gain final result. It is a way we address a math exercise in high shool. It encourages the model reason through intermediate steps before make final answer. By prompting the model with examples of reasoning chains, it can better generalize to new, complex problems. \n",
        "\n",
        "Example: How many rows in string \"hja34r87392rrr83873rrrr\"\n",
        "\n",
        "Without CoT: LLM will start generate: \n",
        "\n",
        "```Number of 'r' in string 'hja34r87392rrr83873rrrr' is 10.\"```\n",
        "\n",
        "With CoT:\n",
        "\n",
        "```\n",
        "Let's count the number of occurrences of the letter 'r' in the string \"hja34r87392rrr83873rrrr\" step by step.\n",
        "\n",
        "Given string:\n",
        "hja34r87392rrr83873rrrr\n",
        "\n",
        "Step-by-step counting:\n",
        "hja34r87392rrr83873rrrr\n",
        "First 'r' at index 5\n",
        "Second 'r' at index 10\n",
        "Third 'r' at index 11\n",
        "Fourth 'r' at index 12\n",
        "Fifth 'r' at index 17\n",
        "Sixth 'r' at index 18\n",
        "Seventh 'r' at index 19\n",
        "Eighth 'r' at index 20\n",
        "Final count:\n",
        "There are 8 occurrences of the letter 'r' in the given string.\n",
        "```\n",
        "\n",
        "* Advantages and Disadvantages\n",
        "\n",
        "**Advantages**\n",
        "\n",
        "- Enhancing performance of LLM when splitting complex tasks step by step. \n",
        "- Easy control and understanding step-by-step generated by LLM.  \n",
        "- More details about solutions help us build a chain of thought.   \n",
        "- Combining more tools or systems to finish a task (Idea of Agents) \n",
        "\n",
        "**Disadvantages** \n",
        "- Depend on prompts \n",
        "- Consuming more tokens because need to process longer -> more cost, and slower \n",
        "- Over fitting when building a solution from prompt, and always keep one way to process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2 Practical Exercises\n",
        "\n",
        "## 2.1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "def parse_amount(amount_str: str) -> float:\n",
        "    \"\"\"Convert string amount to float by removing commas.\"\"\"\n",
        "    return float(amount_str.replace(\",\", \"\"))\n",
        "\n",
        "def extract_amounts(text: str) -> List[float]:\n",
        "    \"\"\"Extract all numeric amounts from input string.\n",
        "    \n",
        "    Args:\n",
        "        text: Input string containing amounts (e.g. \"donate1.23buyapple12,390\")\n",
        "    \n",
        "    Returns:\n",
        "        List of extracted amounts as floats\n",
        "    \"\"\"\n",
        "    DIGITS = set(\"0123456789.,\")\n",
        "    amounts = []\n",
        "    current = []\n",
        "    \n",
        "    for char in text:\n",
        "        if char in DIGITS:\n",
        "            current.append(char)\n",
        "        elif current:\n",
        "            amounts.append(\"\".join(current))\n",
        "            current.clear()\n",
        "            \n",
        "    if current:\n",
        "        amounts.append(\"\".join(current))\n",
        "        \n",
        "    return [parse_amount(amt) for amt in amounts]\n",
        "\n",
        "def format_amount(total_amount: float) -> str:\n",
        "\n",
        "    \"\"\"Format total amount int defined format\"\"\"\n",
        "    str_total_amount = str(total_amount)\n",
        "    cent = str_total_amount.split(\".\")[-1]\n",
        "    if len(cent) == 1: str_total_amount += '0'\n",
        "    \n",
        "    dollar = str_total_amount[:-3]\n",
        "    cent = str_total_amount[-3:]\n",
        "\n",
        "    formatted_dollar = \"\"\n",
        "    for i, digit in enumerate(reversed(dollar)):\n",
        "        if i > 0 and i % 3 == 0:\n",
        "            formatted_dollar = \",\" + formatted_dollar\n",
        "        formatted_dollar = digit + formatted_dollar\n",
        "    \n",
        "    result = formatted_dollar + cent \n",
        "\n",
        "    if result.endswith(\"00\"):\n",
        "        result = result[:-3]\n",
        "    \n",
        "    return result \n",
        "\n",
        "def calculate_total(text: str) -> float:\n",
        "    \"\"\"Calculate total of all amounts in input string.\"\"\"\n",
        "    total_amounts = round(sum(extract_amounts(text)),2)\n",
        "    return format_amount(total_amounts)\n",
        "\n",
        "\"\"\"\n",
        "Floating point will make some issues \n",
        "\n",
        "0.01 + 0.05 -> 0.060000000000000005\n",
        "\n",
        "0.01 + 0.06 -> 0.06999999999999999\n",
        "\n",
        "So I use func round in sum value\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------\n",
            "12,391.23\n",
            "------------------------\n",
            "0.03\n",
            "------------------------\n",
            "6.45\n",
            "------------------------\n",
            "10\n",
            "------------------------\n",
            "0.06\n"
          ]
        }
      ],
      "source": [
        "inputs = [\"donate1.23buyapple12,390\", \"aa0.01t0.02\", \"a1b2c3.45\", \"p0.05c9.95\", \"a0.01b0.05\"]\n",
        "for _input in inputs:\n",
        "    print(\"------------------------\")\n",
        "    print(calculate_total(_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 \n",
        "\n",
        "The company's product currently needs a module to classify medical documents into 10 different types (Patient Records, Prescriptions, Infusion Guidelines, Treatment Protocols, etc.). Given a labeled dataset of pairs (medical document PDF - document type label) \n",
        "\n",
        "Briefly describe a solution that would effectively solve this problem (which model to use, how to train and test, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this requirements we decide into 2 phases in development pace modeling (select solution about model and train/test cycle.)\n",
        "\n",
        "### Phase 1: Modeling\n",
        "\n",
        "\n",
        "#### Summary Requirements\n",
        "Input:\n",
        "Pair (Document - Label): \n",
        "- Labels are from 10 medical document classes.\n",
        "- Documents are PDFs containing medical text of varying lengths.\n",
        "\n",
        "Output:\n",
        "- Model is able to classify medical documents into 10 different types. \n",
        "- Model should handle variable length inputs effectively\n",
        "\n",
        "### Problems Consider \n",
        "- Document length variation\n",
        "- Medical domain \n",
        "- Technical constrain: speed, acc, env of production \n",
        "\n",
        "### Research and discussion  \n",
        "- Model type: Text/Document Classification \n",
        "- Model Options:\n",
        "    + BERT\n",
        "    + Sentence Transformer\n",
        "    + LongFormer (or other variations optimized for long documents)\n",
        "\n",
        "Many models are designed to handle long-context inputs, but in practice, we often set a fixed input size, such as 512 tokens for BERT or Sentence Transformer, or a larger size for LongFormer.\n",
        "\n",
        "- To improve classification performance on long documents, we split each document into multiple chunks, with chunk sizes determined by the model's input limit. During prediction, we classify each chunk individually and use a voting mechanism—averaging the results across all chunks—to determine the final document classification.\n",
        "\n",
        "Final solution: \n",
        "\n",
        "Documents -> N x chunks -> Model (BERT or ST) -> N x classes -> Voting -> Final Class\n",
        "\n",
        "* chunks = input sizes of model \n",
        "* N depend on length of documents (should be get overlap documents)\n",
        "\n",
        "- Extend idea:\n",
        "+ Combine result with full text search use ELK to better results. \n",
        "\n",
        "### Training Stage \n",
        "\n",
        "* Stage 1: Data preprocess: reader, chunking, formatting, splitting train:test:eval ratio \n",
        "    + Train:Test:Eval = 70:15:15\n",
        "\n",
        "* Stage 2: Training  \n",
        "\n",
        "* Stage 3: Evaluating\n",
        "\n",
        "Metrics:\n",
        "    + Acc \n",
        "    + F1 score (if imbalance data)\n",
        "    + Confusion matrix \n",
        "    + Recall/Precision per class \n",
        "\n",
        "\n",
        "### Phase 2: MLOps: Design system to serving model to production \n",
        "\n",
        "![](SystemDesignDocumentClassification.drawio.png)\n",
        "\n",
        "Some notes from design:\n",
        "\n",
        "+ Data Preparation: Documents -> Preprocessing (Reading/Chunking/Splitting) -> Storage (S3 & Database) \n",
        "+ Model Training: Data Retrieval -> Training Model -> Tracking (MLFlow) -> Checkpoint Selection\n",
        "+ Deployment: Best Checkpoint -> Model Transformation (ONNX, TensorRT) -> Containerization (Triton) -> Deployment -> Monitoring\n",
        "\n",
        "+ Trigger CI/CD (Github Action/Jenkins): Automate the deployment process. When a new best checkpoint is identified (e.g., by MLFlow), trigger a CI/CD pipeline to:\n",
        "\n",
        "    + Transform the model.\n",
        "\n",
        "    + Build the container.\n",
        "\n",
        "    + Run tests (unit tests, integration tests).\n",
        "\n",
        "    + Deploy the new model version to serving environment.\n",
        "\n",
        "+ Monitoring: \n",
        "\n",
        "    + System Metrics: CPU usage, memory usage, GPU utilization, request latency, error rates. \n",
        "    + Model Performance Metrics: Track the model's accuracy, precision, recall, etc., in production.\n",
        "    + Data Drift Detection: Compare the distribution of incoming data to the training data distribution. \n",
        "    + Alerting \n",
        "    + Sentry to log bugs of serving services."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
