{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Object Detection \n",
    "\n",
    "Object Detection là một lĩnh vực trong Computer Vision trong việc xác định đối tượng. Object Detection có lẽ là khía cạnh sâu sắc nhất của thị giác máy do số lần sử dụng trong thực tế. \n",
    "\n",
    "Object detection là tác vụ xác định vị trí đối tượng trong hình ảnh, và nó có nhiều ứng dụng thực tiễn trong cuộc sống như nhận dạng mặt người, hệ thống xe tự lái...\n",
    "\n",
    "Nhiệm vụ object detection là tìm được đường bao quanh đối tượng. Như hình bên dưới minh họa \n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*95lJePt-70PH3PoVfz2yYQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các thuật toán object detection \n",
    "\n",
    "Trong giai đoạn chưa deep learning phát triển thì việc áp dụng cho bài toán object detection đã có những bước khẳng định đầu tiên với phương pháp dựa trên lý machine learning cơ bản.\n",
    "\n",
    "1. Sliding windown \n",
    "\n",
    "Cửa sổ trượt một khái niệm không còn xa lạ với bất kể ai từng học về machine learning, về bản chất nó là một hình chữ nhật trượt lần lượt qua hình ảnh để lấy từng vùng trong ảnh.\n",
    "\n",
    "Và tư tưởng ban đầu bài toán object detection bắt nguồn từ đó. Một cửa sổ trượt trượt qua lần lượt từng vị trí trong hình ảnh, mỗi hình ảnh từ cửa sổ trượt được trích đặc trưng bởi thuật toán trích đặc trưng HOG, SIFT, SUFT,... sau đó áp dụng bộ phân loại SVM, MLP để phân loại đối tượng. \n",
    "\n",
    "Tham khảo project: https://github.com/ngoctuhan/When-i-learn-Machine-Learning-from-Zero/tree/master/Detection%20Person%20HOG%20%2B%20SVM\n",
    "\n",
    "Nhược điểm của nó là gì: \n",
    "\n",
    "Đó là tốc độ và sự hiệu quả: tốc độ chúng ta cần rất nhiều của sổ có kích thước khác nhau để tìm được đối tượng có kích thước khác nhau, điều này gây sự bùng nổ tính toán. Chưa kể sự chính xác của việc trích đặc trưng phụ thuộc rất nhiều yếu tố khiến cho việc sai xót điều k thể tranh cãi. \n",
    "\n",
    "Nhưng thật may mắn chúng ta đã có deep learning nó khác phục được các nhược điểm trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Nhóm thuật toán sử dụng deep learning. \n",
    "\n",
    "Việc áp dụng đột phát và nhanh cóng của deep learning vào năm 2012 đã đưa vào sự tồn tại các thuật toán và phương pháp phát hiện đối tượng hiện đại và chính xác cao như R-CNN, Fast-RCNN, Faster-RCNN, RetinaNet và nhanh hơn nhưng rất chính xác như SSD và YOLO. Sử dụng các phương pháp và thuật toán này, dựa trên deep learning và cũng dựa trên việc học máy đòi hỏi rất nhiều kiến thức về toán học và việc học sâu. Có hàng triệu chuyên gia lập trình và các nhà phát triển phần mềm muốn tích hợp và tạo ra các sản phẩm mới sử dụng object detection. Nhưng công nghệ này xa tầm tay của họ và phức tạp để hiểu và sử dụng thực tế của nó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ cố gắng khám phá một vòng các thuật toán và sẽ cố gắng thực hiện một mini project trong tương lại. \n",
    "\n",
    "Trước hết tại sao tác vụ này không thể sử dụng được một mạng CNN tiêu chuẩn theo sau là các lớp kết nối đầy đủ, có lí do đơn giản, cùng một đối tượng trên các hình ảnh khác nhau nó thể nằm các vị trí khác nhau như vậy đầu ra không cố định, Một cách tiếp cận ngây thơ là tìm nhiều khu vực lớn hơn rồi áp dụng một bộ phân loại sử dụng CNN tiêu chuẩn. Vâng chúng ta cần rất nhiều vùng quan tâm khác nhau từ hình ảnh và sử dụng CNN để phân loại sự hiện diện của đối tượng trong khu vực đó. Vấn đề với phương pháp này là các đối tượng quan tâm có thể có các vị trí không gian khác nhau trong ảnh và các tỷ lệ khung hình khác nhau. Do đó, bạn sẽ phải chọn một số lượng lớn các khu vực và điều này có thể tính toán nổ tung\n",
    "\n",
    "\n",
    "* R-CNN:  \n",
    "\n",
    "Để bỏ qua một số lượng lớn các vùng quan tâm thì  Ross Girshick et al đã đề xuất một phương pháp trong đó chúng tôi sử dụng tìm kiếm có chọn lọc để trích xuất chỉ 2000 vùng từ hình ảnh và ông gọi chúng là các đề xuất khu vực. Do đó thay vì cố gắng phân loại rất rất nhiều vùng thì giờ chỉ còn 2000 vùng từ hình ảnh.\n",
    "\n",
    "Thuật toán tìm kiếm có chọn lọc( selective search)\n",
    "\n",
    "1. Tạo nhiều vùng, mỗi vùng thuộc tối đa một đối tượng. Sử dụng phương pháp được mô tả bởi Felzenzwalb et al, chúng tôi tạo ra nhiều khu vực ứng cử viên. ( việc tạo vùng đối tượng ban đầu phần lớn sử dụng kĩ thuật liên quan sự tương đồng màu sắc, kết cấu, kích thước,... các pixel để xác định).\n",
    "\n",
    "![](images/RCNN.png)\n",
    "\n",
    "2. Sử dụng thuật toán tham lam để kết hợp đệ quy các khu vực tương tự thành các khu vực lớn hơn.\n",
    "\n",
    "    2.1. Từ tập hợp các vùng, chọn hai vùng giống nhau nhất.\n",
    "    \n",
    "    2.2. Kết hợp chúng thành một khu vực duy nhất, lớn hơn.\n",
    "    \n",
    "    2.3. Lặp lại cho đến khi chỉ còn một vùng.\n",
    "\n",
    "![](images/RCNN2.png)\n",
    "\n",
    "3. Sử dụng các khu vực được tạo để tạo đề xuất khu vực ứng cử viên cuối cùng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selective Search được public như một thư viện trong python:\n",
    "   \n",
    "   \n",
    "Install: pip install selective-search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from selective_search import selective_search\n",
    "\n",
    "# Load image as NumPy array from image files\n",
    "image = skimage.io.imread('path/to/image')\n",
    "\n",
    "# Run selective search using single mode\n",
    "boxes = selective_search(image, mode='single', random=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các vấn đề với R-CNN:\n",
    "\n",
    "Vẫn cần một lượng lớn thời gian để đào tạo mạng vì bạn sẽ phải phân loại 2000 đề xuất khu vực cho mỗi hình ảnh.\n",
    "\n",
    "Nó không thể được thực hiện theo thời gian thực vì phải mất khoảng 47 giây cho mỗi hình ảnh thử nghiệm.\n",
    "\n",
    "Thuật toán tìm kiếm chọn lọc là một thuật toán cố định. Do đó, không có học tập đang xảy ra ở giai đoạn đó. Điều này có thể dẫn đến việc tạo ra các đề xuất khu vực ứng cử viên xấu.\n",
    "\n",
    "* Fast RCNN\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*0pMP3aY8blSpva5tvWbnKA.png)\n",
    "\n",
    "Chính tác giả của RCNN đưa ra phương pháp giúp cải thiện hiệu năng của RCNN\n",
    "\n",
    "Các tiếp cận của nó cũng tượng tự R-CNN ban đầu cũng sử dụng tìm kiếm chọn lọc  tao ra đề xuất khu vực nhưng bây giờ các đề xuất khu vực này không còn đưa qua cho CNN nữa. \n",
    "\n",
    "Hình ảnh đầu vào sẽ được cho qua mạng CNN để tạo ra bản đồ tính năng: giả sử chung ta sử dụng mạng CNN là VGG16 \n",
    "\n",
    "![](https://miro.medium.com/max/1400/0*OVMjbYdDqpf3avlh.png)\n",
    "\n",
    "Hình ảnh đầu vào có kích thước 512 x 512 x 3 và sau qua VGG16 chúng ta được bản đồ tính năng là 16x16x512.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quan sát biểu đồ tính năng có kích thước 512/16 lần so với đầu vào điều này là quan trọng.\n",
    "\n",
    "![](https://miro.medium.com/max/1400/0*Ye1ZZL6zn6QXWbxw.jpg)\n",
    "\n",
    "Gỉa sử bằng thuật toán đề xuất khu vực chúng ta ROI đến vùng như trong hình. Về bản chất ROI không phải là hộp giới hạn, nó là vùng quan tâm vùng đề cử và cần được tính toán thêm. Vùng ROI này có thể được xác định từ 2000 box từ thuật toán tìm kiếm chọn lọc.\n",
    "\n",
    "Bây giờ chúng ta chuyển từ ROI bản đồ đầu vào thành ROI trên bản đồ tính năng. \n",
    "\n",
    "Vậy làm cách nào?\n",
    "\n",
    "Mỗi RoI đều có tọa độ và kích thước ban đầu. Gỉa sử ta xét 1 ROI để dễ dàng quan sát:\n",
    "\n",
    "Kích thước ban đầu của nó là 145x200 và góc trên cùng bên trái được đặt thành (192x296) . Như bạn có thể nói, chúng tôi không thể chia hầu hết các số đó cho 32 (hệ số tỷ lệ).\n",
    "\n",
    "chiều rộng: 200/32 = 6,25\n",
    "\n",
    "chiều cao: 145/32 = ~ 4,53\n",
    "\n",
    "x: 296/32 = 9,25\n",
    "\n",
    "y: 192/32 = 6\n",
    "\n",
    "Từ đó ta xác định được khu vực ROI trên bản đồ tính năng:\n",
    "\n",
    "![](https://miro.medium.com/max/1400/0*itjjLvxulVdeHboj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các cell đã được chia 16x16 tức tế bào đơn vị đã là 1 nên k thể để TH tọa độ lẻ như vậy được nên chúng ta cần thực hiện phép làm tròn 6,25 thành 6 và 4.53 thành 4. Bạn có thể nhận thấy rằng chúng ta vừa mất một loạt dữ liệu (màu xanh đậm) và có được dữ liệu mới (màu xanh lá cây):\n",
    "\n",
    "![](https://miro.medium.com/max/1400/0*W_0kPRvx-vkLxMNm.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giời khi có bản đồ ROI trên bản đồ tính năng chúng ta sẽ RoI Pooling điều này giúp chúng ta tạo nên các vùng ROI có kích thước như nhau và thuật toán cho việc tính toán sau này.\n",
    "\n",
    "Tại sao lại dùng ROI pooling:\n",
    "\n",
    "Sau RoI Pooling Layer, có một lớp được kết nối đầy đủ với kích thước cố định. Bởi vì các RoI của chúng tôi có các kích thước khác nhau, chúng tôi phải gộp chúng thành cùng một kích thước ( ví dụ 3x3x512 ). Tại thời điểm này, RoI được ánh xạ của chúng tôi có kích thước 4x6x512 và như bạn có thể tưởng tượng, chúng tôi không thể chia 4 cho 3 :(. Đó là nơi lượng tử hóa lại xuất hiện)\n",
    "\n",
    "![](https://miro.medium.com/max/1400/0*hWRZgO7YQTqjquIA.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qúa trình ROI pool được thực hiện như hình bên dưới:\n",
    "\n",
    "![](https://miro.medium.com/max/1400/0*SMrADTLV_u9SQ6EV.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta thầy việc ROI pooling làm không sử dụng hết toàn bộ diện tích khu vực ROI và khi đó chúng ta bị mất thêm tính năng, Đây có thể là một vấn đề bởi vì mỗi ô di động, có chứa một lượng dữ liệu khổng lồ (1x1x512 trên bản đồ tính năng dịch một cách lỏng lẻo thành 32x32x3 trên ảnh gốc nhưng vui lòng không sử dụng tham chiếu đó, vì đó không phải là cách hoạt động của lớp chập). Có một cách để khắc phục điều đó (RoIAlign) và tôi sẽ sớm viết một bài viết thứ hai về nó. \n",
    "\n",
    "Và chúng ta được một đầu ra như này: \n",
    "\n",
    "![](https://miro.medium.com/max/1056/0*PV3fmXrcohjrGFo_.png)\n",
    "\n",
    "\n",
    "Sau khi tổng hợp xong, chúng tôi chắc chắn rằng đầu vào của chúng tôi có kích thước 3x3x512 để chúng tôi có thể đưa nó vào các lớp FC để xử lý thêm. Sử dụng lớp softmax để dự đoán lớp của khu vực được đề xuất và cả các giá trị bù cho hộp giới hạn.\n",
    "\n",
    "Đó là cách Fast RCNN hoạt động, dĩ nhiên nó cơ phiên bản cái tiến tại phần ROI pooling để tránh làm mất mát thêm dữ liệu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Faster RCNN \n",
    "\n",
    "Một trong những vẫn đề của Fast RCNN hay RCNN là sử dụng tìm kiếm chọn lọc đưa ra các khu vực đề xuất. Thuật toán này tiêu tốn khá nhiều thời gian khiến cho mô hình không thể chạy với thời gian thực. Vì vậy cần có một phương pháp nào đó loại quá trình sử dụng tìm kiếm chọn lọc để đưa ra các khu vực đề xuất.\n",
    "\n",
    "Chính vì lẻ đó Shaoqing Ren et al đã tìm ra một phương pháp loại bỏ điều đó:\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*pSnVmJCyQIRKHDPt3cfnXA.png)\n",
    "\n",
    "RPN\n",
    "\n",
    "RPN giải quyết các vấn đề trên bằng cách huấn luyện mạng neural network để đảm nhận thay vai trò của các thuật toán như selective search vốn rất chậm chạp.\n",
    "\n",
    "Một Region Proposal Network nhận đầu vào là ảnh với kích thước bất kì và cho đầu ra là region proposal (tập vị trí của các hình chữ nhật có thể chứa vật thể), cùng với xác suất chứa vật thể của hình chữ nhật tương ứng.\n",
    "\n",
    "Cách hoạt động RPN có 2 bước chính:\n",
    "\n",
    "Bước 1: Feed-forward ảnh qua CNN thu được convolutional features.\n",
    "\n",
    "Trong bài báo gốc, tác giả đã nhắc đến nhiều các mạng Convolution Network có sẵn như VGG-16, ZFNet, để dễ dàng cho việc giải thích, chúng ta sẽ lấy ví dụ ở đây là mạng VGG-16.\n",
    "\n",
    "Mạng VGG-16 chứa 13 convolutions layer kích thước 3×3 cùng với 5 max pooling layer kích thước 2×2. Khi đầu vào là một ảnh có kích thước 3×W×H , đầu ra sẽ nhận được 3×W′×H′ với W′=W/16 H′=H/16\n",
    "\n",
    "Bước 2: Sử dụng một cửa sổ trượt lên convolutional features.\n",
    "\n",
    "![](https://deepmlml.com/images/rpn/rpn.png)\n",
    "\n",
    "Để tạo ra region proposals, chúng ta sử dụng một network hay còn gọi là cửa sổ trượt (sliding-window) kích thước n×n trượt trên convolutional features. Đầu ra của network này là đầu vào của 2 fully-connected layer dự đoán vị trí của regions (box-regression layer), cũng như xác suất chứa object(box-classification) của hộp ấy. Tại mỗi vị trí của cửa sổ trượt chúng ta dự đoán đồng thời nhiều nhiều region proposal cùng một lúc, với k là số proposal tương ứng với mỗi vị trí. Vậy reg layer có 4k đầu ra dự đoán vị trí của k proposal, cls layer chứa 2k đầu ra dự đoán xác suất chứa vật thể của proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhiều bạn thắc mắc tại sao lại có 2k scores và 4k coordinates, với mỗi sile windown trên biểu đồ tính năng chúng ta có thể lấy được k hình chữ nhật bên trong silding windown đó. Và mỗi hình đó chúng ta dự đoán xem nó có phải là đối tượng không nên bài toán là phân loại 2 lớp, phần còn lại là reg layer là dự đoán bouding box của đối tượng đó.\n",
    "\n",
    "Tại sao phải tạo ra những anchors này. Theo cách hiểu của bản thân tôi thì, trong bài toán xác định vị trí vật thể, số lượng đầu ra của mỗi ảnh là khác nhau. Ví dụ một bức ảnh có thể có 2 vật thể, một bức ảnh khác có 4 vật thể. Vì số lượng output là không cố định ta phải dựa vào các anchor để cố định hóa số lượng output này.\n",
    "\n",
    "![](images/anchors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi đã có đầu ra của các region proposal, chúng ta sẽ tìm hiểu về khái niệm anchors. Tại mỗi vị trí của sliding window trên convolutional features, chúng ta tạo ra k anchors tương ứng ở hình ảnh gốc. Trong bài báo, tác giả sử dụng 1 hình vuông, 2 hình chữ nhật với tỉ lệ chiều rộng, chiều dài là 1-2, 2-1, cùng với 3 kích cỡ khác nhau, như vậy k=3×3=9.\n",
    "\n",
    "Các anchors này sẽ được gán mác là positive hoặc negative dựa vào diện tích overlap với ground truth box theo luật như sau.\n",
    "\n",
    "Các anchor được phân loại là positive nếu\n",
    "\n",
    "* Là anchor có tỉ lệ diện tích chồng chéo trên diện tích chồng chập (Intersection-over- Union - viết tắt IoU) overlap lớn nhất với một ground truth box.\n",
    "* Là anchor có tỉ lệ IoU với một ground truth lớn hơn 0.7\n",
    "* Các anchor được phân noại là negative nếu có giá trị IoU bé hơn 0.3\n",
    "\n",
    "Các anchor không thỏa mãn 2 điều kiện nêu trên thì bỏ qua. Không được đánh giá trong quá trình training object.\n",
    "\n",
    "Tại sao phải tạo ra những anchors này. Câu trả lời gồm 2 nguyên nhân chính\n",
    "\n",
    "* Dựa phân loại của anchor, để dự đoán xác suất chứa vật thể của các region proposal\n",
    "* Dựa vào khoảng cách từ anchor đến ground truth box, để dự đoán vị trí của bounding box.\n",
    "\n",
    "Từ đây ta xác định được tiêu đầu ra của box-regression layer và box-classification được nhắc tới ở phần cấu trúc mạng RPN.\n",
    "\n",
    "* Box-classification dự đoán xác suất chứa vật thể của k region proposal, tương ứng với k anchor tại từng vị trí của sliding-window.\n",
    "* Box-regression dự đoán khoảng cách tư anchor đến ground truth box tương ứng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm loss cho Faster RCNN\n",
    "\n",
    "Chúng ta thầy có 2 nhiệm vụ trong bài là phân loại và reg box\n",
    "\n",
    "Nên hàm loss được định nghĩa như sau:\n",
    "\n",
    "$L(\\{ p_i \\}, \\{ t_i \\}) = \\frac{1}{N_{cls}} \\sum_{i} L_{cls} (p_i, p_i^{*}) + \\lambda \\frac{1}{N_{reg}} \\sum_{i} p_i^{*} L_{reg}(t_i, t_i^{*})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với i là index của anchor trong mini-batch và pi là xác suất dự đoán của anchor i là một đối tượng. Giá trị nhãn ground-truth p∗i là một nếu anchor là positive, và là không khi anchor là negative. \n",
    "\n",
    "* $t_i$  là một vector 4 chiều biểu diễn giá trị tọa độ của bounding box đã được dự đoán.\n",
    "* $t^*_i$ là vector 4 chiều biểu diễn giá trị tọa độ của ground-truth box tương ứng với positive anchor.\n",
    "* $L_{cls}$ là log loss của 2 class (object và non-object)\n",
    "* $L_{reg}$ dùng SmoothL1Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức tính Smooth L1 \n",
    "\n",
    "$loss(x, y) = \\sum \\begin{cases}\n",
    "0.5 * (x_i - y_i)^2, if |x_i - y_i| < 1 \\\\\n",
    "|x_i - y_i| - 0.5, otherwise\n",
    "\\end{cases} \\quad\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm loss của 2 nhiệm vụ đều dựa theo tư tưởng chính hàm cross entropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
